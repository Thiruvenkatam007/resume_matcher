{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ec5095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "NexResume Pipeline (Refactored):\n",
    "- Robust PDF parsing (pypdf -> pdfminer.six fallback)\n",
    "- Structured LLM outputs via Pydantic (no more JSON guessing)\n",
    "- Deterministic scoring (optional, based on JD weights)\n",
    "- Chunking for long resumes to avoid token cutoffs\n",
    "- Concurrency + retries + logging\n",
    "- CSV summary aggregation\n",
    "\n",
    "Usage:\n",
    "  python nexresume_refactor.py --job path/to/job.yml --resumes path/to/resumes_folder [--workers 4]\n",
    "\n",
    "Requires:\n",
    "  pip install langchain-openai langchain pydantic backoff pypdf pdfminer.six pyyaml numpy\n",
    "  export OPENAI_API_KEY=...\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# LangChain (modern imports)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "import backoff\n",
    "import numpy as np\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85daa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13320\\599226424.py:168: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  _embedder = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "2025-09-20 12:26:44,331 INFO PyTorch version 2.7.1 available.\n",
      "2025-09-20 12:26:45,642 INFO Use pytorch device_name: cpu\n",
      "2025-09-20 12:26:45,643 INFO Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-09-20 12:26:50,492 INFO Pre-filter selected 1/1 resumes via embeddings\n",
      "2025-09-20 12:26:52,810 INFO HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 12:26:57,672 INFO Wrote reports\\summary.csv\n",
      "2025-09-20 12:26:57,673 INFO Done processing resumes in 19.6s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "NexResume Pipeline (Refactored):\n",
    "- Robust PDF parsing (pypdf -> pdfminer.six fallback)\n",
    "- Structured LLM outputs via Pydantic (no more JSON guessing)\n",
    "- Deterministic scoring (optional, based on JD weights)\n",
    "- Chunking for long resumes to avoid token cutoffs\n",
    "- Concurrency + retries + logging\n",
    "- CSV summary aggregation\n",
    "\n",
    "Usage:\n",
    "  python nexresume_refactor.py --job path/to/job.yml --resumes path/to/resumes_folder [--workers 4]\n",
    "\n",
    "Requires:\n",
    "  pip install langchain-openai langchain pydantic backoff pypdf pdfminer.six pyyaml numpy sentence-transformers torch --upgrade\n",
    "  export OPENAI_API_KEY=...\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# LangChain (modern imports)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "import backoff\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "# ========== Logging ==========\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")\n",
    "\n",
    "# ========== IO helpers ==========\n",
    "\n",
    "def load_yaml_job_description(path: str) -> Dict[str, Any]:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        jd = yaml.safe_load(f) or {}\n",
    "    return jd\n",
    "\n",
    "\n",
    "def _read_pdf_pypdf(file_path: str) -> str:\n",
    "    try:\n",
    "        from pypdf import PdfReader\n",
    "    except Exception:  # pragma: no cover\n",
    "        return \"\"\n",
    "    try:\n",
    "        text = []\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            reader = PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                try:\n",
    "                    text.append(page.extract_text() or \"\")\n",
    "                except Exception:\n",
    "                    text.append(\"\")\n",
    "        return \"\\n\".join(text)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"pypdf failed on {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _read_pdf_pdfminer(file_path: str) -> str:\n",
    "    try:\n",
    "        # pdfminer.six\n",
    "        from pdfminer.high_level import extract_text\n",
    "        return extract_text(file_path) or \"\"\n",
    "    except Exception as e:  # pragma: no cover\n",
    "        logging.warning(f\"pdfminer failed on {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def load_resume_text(file_path: str) -> str:\n",
    "    file_path = str(file_path)\n",
    "    if file_path.lower().endswith('.txt'):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not read TXT {file_path}: {e}\")\n",
    "            return \"\"\n",
    "    elif file_path.lower().endswith('.pdf'):\n",
    "        text = _read_pdf_pypdf(file_path)\n",
    "        if not text.strip():\n",
    "            text = _read_pdf_pdfminer(file_path)\n",
    "        if not text.strip():\n",
    "            logging.warning(f\"Could not extract text from PDF {file_path}\")\n",
    "        return text\n",
    "    else:\n",
    "        logging.warning(f\"Unsupported resume format: {file_path}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def safe_candidate_name_from_file(file_name: str) -> str:\n",
    "    stem = Path(file_name).stem\n",
    "    return re.sub(r\"[^A-Za-z0-9_.-]\", \"_\", stem)\n",
    "\n",
    "# ========== Chunking ==========\n",
    "\n",
    "def chunk_text(text: str, max_chars: int = 6000, overlap: int = 300) -> List[str]:\n",
    "    \"\"\"Simple char-based chunking to keep prompts within context.\n",
    "    Adjust max_chars based on your target model context window.\n",
    "    \"\"\"\n",
    "    text = text or \"\"\n",
    "    if len(text) <= max_chars:\n",
    "        return [text]\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        chunks.append(text[i:i + max_chars])\n",
    "        i += max_chars - overlap\n",
    "    return chunks\n",
    "\n",
    "# ========== Pydantic schema for structured output ==========\n",
    "\n",
    "class MatchReport(BaseModel):\n",
    "    matched_required_skills: List[str] = []\n",
    "    missing_required_skills: List[str] = []\n",
    "    matched_optional_skills: List[str] = []\n",
    "    education_match: str\n",
    "    experience_match: str\n",
    "    keywords_matched: List[str] = []\n",
    "    soft_skills_match: List[str] = []\n",
    "    resume_summary: str\n",
    "    match_score: float = Field(ge=0, le=1)\n",
    "    city_tier_match: bool\n",
    "    longest_tenure_months: int\n",
    "    final_score: int = Field(ge=0, le=100)\n",
    "\n",
    "# ========== Prompt ==========\n",
    "\n",
    "PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a precise resume matching assistant. \"\n",
    "               \"Compare the job description and resume content to fill the schema exactly.\"),\n",
    "    (\"user\",\n",
    "     \"Job Description (YAML):\\n{job_description}\\n\\n\"\n",
    "     \"Resume chunk:\\n{resume_text}\\n\\n\"\n",
    "     \"Return ONLY JSON compatible with the provided schema (no markdown, no prose).\")\n",
    "])\n",
    "\n",
    "# ========== Embeddings (pre-filter) ==========\n",
    "\n",
    "def _cosine(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    if a is None or b is None:\n",
    "        return -1.0\n",
    "    na = np.linalg.norm(a); nb = np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0:\n",
    "        return -1.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "_embedder: Optional[SentenceTransformerEmbeddings] = None\n",
    "\n",
    "def get_embedder() -> SentenceTransformerEmbeddings:\n",
    "    global _embedder\n",
    "    if _embedder is None:\n",
    "        _embedder = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    return _embedder\n",
    "\n",
    "def embed_text(text: str) -> np.ndarray:\n",
    "    emb = get_embedder().embed_query(text or \"\")\n",
    "    return np.array(emb, dtype=np.float32)\n",
    "\n",
    "\n",
    "def prefilter_resumes(jd: Dict[str, Any], resume_paths: List[Path], texts: List[str], topk: Optional[int] = None, topk_frac: float = 0.4) -> List[Tuple[Path, float]]:\n",
    "    \"\"\"Rank resumes by embedding similarity to the JD and return the top subset.\n",
    "    If topk is None, select ceil(len(resumes) * topk_frac). Never fewer than 1.\n",
    "    \"\"\"\n",
    "    jd_text = yaml.dump(jd, sort_keys=False)\n",
    "    jd_vec = embed_text(jd_text)\n",
    "\n",
    "    sims: List[Tuple[int, float]] = []\n",
    "    for i, t in enumerate(texts):\n",
    "        try:\n",
    "            v = embed_text(t)\n",
    "            sims.append((i, _cosine(jd_vec, v)))\n",
    "        except Exception:\n",
    "            sims.append((i, -1.0))\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    n = len(resume_paths)\n",
    "    k = int(topk) if topk is not None else int(np.ceil(max(1, n) * float(topk_frac)))\n",
    "    k = max(1, min(n, k))\n",
    "\n",
    "    selected = [(resume_paths[i], score) for i, score in sims[:k]]\n",
    "    return selected\n",
    "\n",
    "# ========== LLM client ==========\n",
    "key = os.getenv(\"OPENROUTER_API_KEY\", \"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\")\n",
    "base = os.getenv(\"OPENROUTER_BASE\", \"https://openrouter.ai/api/v1\")\n",
    "model = os.getenv(\"MODEL_NAME\", \"nvidia/nemotron-nano-9b-v2:free\")\n",
    "def make_llm(model: str = \"gpt-4o-mini\", temperature: float = 0.6):\n",
    "    llm = ChatOpenAI(model=model, temperature=temperature, api_key=key, base_url=base)\n",
    "    return llm.with_structured_output(MatchReport)\n",
    "\n",
    "# ========== Retry wrapper ==========\n",
    "\n",
    "@backoff.on_exception(backoff.expo, Exception, max_time=90)\n",
    "def call_llm_structured(structured_llm, jd_dict: Dict[str, Any], resume_text: str) -> MatchReport:\n",
    "    msg = PROMPT.format(job_description=yaml.dump(jd_dict, sort_keys=False),\n",
    "                        resume_text=resume_text)\n",
    "    \n",
    "    # IMPORTANT: for structured outputs, invoke with messages\n",
    "    return structured_llm.invoke(msg)\n",
    "\n",
    "# ========== Deterministic scoring (optional) ==========\n",
    "\n",
    "def normalize_skill(s: str) -> str:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    aliases = {\n",
    "        \"js\": \"javascript\",\n",
    "        \"nodejs\": \"node.js\",\n",
    "        \"py\": \"python\",\n",
    "        \"torch\": \"pytorch\",\n",
    "    }\n",
    "    return aliases.get(s, s)\n",
    "\n",
    "\n",
    "def compute_deterministic_score(jd: Dict[str, Any], parsed: Dict[str, Any]) -> Tuple[int, Dict[str, float]]:\n",
    "    \"\"\"Compute a reproducible final score from components.\n",
    "    JD may include optional weights:\n",
    "      weights: {required:0.45, optional:0.2, experience:0.15, education:0.1, location:0.1}\n",
    "    Fallback defaults used if missing.\n",
    "    \"\"\"\n",
    "    weights = {\n",
    "        \"required\": 0.45,\n",
    "        \"optional\": 0.20,\n",
    "        \"experience\": 0.15,\n",
    "        \"education\": 0.10,\n",
    "        \"location\": 0.10,\n",
    "    }\n",
    "    jd_weights = (jd or {}).get(\"weights\") or {}\n",
    "    weights.update({k: float(v) for k, v in jd_weights.items() if k in weights})\n",
    "\n",
    "    req = [normalize_skill(s) for s in (jd.get(\"required_skills\") or [])]\n",
    "    opt = [normalize_skill(s) for s in (jd.get(\"optional_skills\") or [])]\n",
    "\n",
    "    matched_req = set(normalize_skill(s) for s in (parsed.get(\"matched_required_skills\") or []))\n",
    "    matched_opt = set(normalize_skill(s) for s in (parsed.get(\"matched_optional_skills\") or []))\n",
    "\n",
    "    req_cov = (len(matched_req & set(req)) / max(1, len(req))) if req else 0.0\n",
    "    opt_cov = (len(matched_opt & set(opt)) / max(1, len(opt))) if opt else 0.0\n",
    "\n",
    "    # naive booleans from strings\n",
    "    exp_fit = 1.0 if str(parsed.get(\"experience_match\", \"\")).lower().startswith((\"true\", \"yes\")) else 0.5\n",
    "    edu_fit = 1.0 if str(parsed.get(\"education_match\", \"\")).lower().startswith((\"true\", \"yes\")) else 0.5\n",
    "    loc_fit = 1.0 if bool(parsed.get(\"city_tier_match\")) else 0.0\n",
    "\n",
    "    score = (\n",
    "        weights[\"required\"] * req_cov +\n",
    "        weights[\"optional\"] * opt_cov +\n",
    "        weights[\"experience\"] * exp_fit +\n",
    "        weights[\"education\"] * edu_fit +\n",
    "        weights[\"location\"] * loc_fit\n",
    "    )\n",
    "    return int(round(score * 100)), {\n",
    "        \"req_cov\": req_cov,\n",
    "        \"opt_cov\": opt_cov,\n",
    "        \"exp_fit\": exp_fit,\n",
    "        \"edu_fit\": edu_fit,\n",
    "        \"loc_fit\": loc_fit,\n",
    "    }\n",
    "\n",
    "# ========== Per-resume processing ==========\n",
    "\n",
    "def merge_chunk_reports(reports: List[MatchReport]) -> Dict[str, Any]:\n",
    "    \"\"\"Merge multiple chunk-level reports into one resume-level report.\n",
    "    Strategy: union for lists, max for tenure and scores, any True for booleans, longest summary.\n",
    "    \"\"\"\n",
    "    if not reports:\n",
    "        return {}\n",
    "\n",
    "    out: Dict[str, Any] = {\n",
    "        \"matched_required_skills\": set(),\n",
    "        \"missing_required_skills\": set(),\n",
    "        \"matched_optional_skills\": set(),\n",
    "        \"education_match\": \"\",\n",
    "        \"experience_match\": \"\",\n",
    "        \"keywords_matched\": set(),\n",
    "        \"soft_skills_match\": set(),\n",
    "        \"resume_summary\": \"\",\n",
    "        \"match_score\": 0.0,\n",
    "        \"city_tier_match\": False,\n",
    "        \"longest_tenure_months\": 0,\n",
    "        \"final_score\": 0,\n",
    "    }\n",
    "\n",
    "    for r in reports:\n",
    "        data = r.model_dump()\n",
    "        out[\"matched_required_skills\"].update(data.get(\"matched_required_skills\", []))\n",
    "        out[\"missing_required_skills\"].update(data.get(\"missing_required_skills\", []))\n",
    "        out[\"matched_optional_skills\"].update(data.get(\"matched_optional_skills\", []))\n",
    "        out[\"keywords_matched\"].update(data.get(\"keywords_matched\", []))\n",
    "        out[\"soft_skills_match\"].update(data.get(\"soft_skills_match\", []))\n",
    "        if len((data.get(\"resume_summary\") or \"\")) > len(out[\"resume_summary\"]):\n",
    "            out[\"resume_summary\"] = data.get(\"resume_summary\") or \"\"\n",
    "        out[\"match_score\"] = max(out[\"match_score\"], float(data.get(\"match_score\") or 0))\n",
    "        out[\"city_tier_match\"] = out[\"city_tier_match\"] or bool(data.get(\"city_tier_match\"))\n",
    "        out[\"longest_tenure_months\"] = max(out[\"longest_tenure_months\"], int(data.get(\"longest_tenure_months\") or 0))\n",
    "        out[\"final_score\"] = max(out[\"final_score\"], int(data.get(\"final_score\") or 0))\n",
    "        # keep the most \"positive\" education/experience note if any\n",
    "        if str(data.get(\"education_match\", \"\")).lower().startswith((\"true\", \"yes\")):\n",
    "            out[\"education_match\"] = str(data.get(\"education_match\"))\n",
    "        if str(data.get(\"experience_match\", \"\")).lower().startswith((\"true\", \"yes\")):\n",
    "            out[\"experience_match\"] = str(data.get(\"experience_match\"))\n",
    "\n",
    "    # convert sets back to lists\n",
    "    for k in (\"matched_required_skills\", \"missing_required_skills\", \"matched_optional_skills\",\n",
    "              \"keywords_matched\", \"soft_skills_match\"):\n",
    "        out[k] = sorted(out[k])\n",
    "    return out\n",
    "\n",
    "\n",
    "def process_one_resume(jd: Dict[str, Any], resume_path: Path, structured_llm) -> Optional[Dict[str, Any]]:\n",
    "    text = load_resume_text(str(resume_path))\n",
    "    if not text.strip():\n",
    "        logging.warning(f\"Empty/unsupported resume: {resume_path.name}; skipping.\")\n",
    "        return None\n",
    "\n",
    "    # chunk & score each chunk\n",
    "    chunks = chunk_text(text)\n",
    "    chunk_reports: List[MatchReport] = []\n",
    "    for ch in chunks:\n",
    "        try:\n",
    "            r = call_llm_structured(structured_llm, jd, ch)\n",
    "            chunk_reports.append(r)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"LLM error on {resume_path.name} chunk: {e}\")\n",
    "\n",
    "    if not chunk_reports:\n",
    "        logging.warning(f\"No LLM outputs for {resume_path.name}\")\n",
    "        return None\n",
    "\n",
    "    merged = merge_chunk_reports(chunk_reports)\n",
    "\n",
    "    # Optional deterministic override/consistency check\n",
    "    det_score, components = compute_deterministic_score(jd, merged)\n",
    "    merged[\"final_score_deterministic\"] = det_score\n",
    "    merged[\"scoring_components\"] = components\n",
    "\n",
    "    candidate = safe_candidate_name_from_file(resume_path.name)\n",
    "    report = {\n",
    "        \"candidate_name\": candidate,\n",
    "        \"job_title\": jd.get(\"Job_Title\") or jd.get(\"job_title\"),\n",
    "        **merged,\n",
    "    }\n",
    "    return report\n",
    "\n",
    "# ========== Batch processing ==========\n",
    "\n",
    "def process_all(job_description_file: str, resumes_folder: str, workers: int = 4, model: str = \"gpt-4o-mini\", topk: Optional[int] = None, topk_frac: float = 0.4) -> None:\n",
    "    reports_dir = Path(\"reports\"); reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    jd = load_yaml_job_description(job_description_file)\n",
    "    structured_llm = make_llm(model=model)\n",
    "\n",
    "    resume_files = [Path(resumes_folder) / fn for fn in os.listdir(resumes_folder)\n",
    "                    if fn.lower().endswith((\".pdf\", \".txt\"))]\n",
    "\n",
    "    reports: List[Dict[str, Any]] = []\n",
    "\n",
    "    # --- Load texts once for embedding + later scoring ---\n",
    "    resume_texts = [load_resume_text(str(p)) for p in resume_files]\n",
    "\n",
    "    # --- Pre-filter via embeddings ---\n",
    "    ranked = prefilter_resumes(jd, resume_files, resume_texts, topk=topk, topk_frac=topk_frac)\n",
    "    selected_files = [p for p, _ in ranked]\n",
    "    logging.info(f\"Pre-filter selected {len(selected_files)}/{len(resume_files)} resumes via embeddings\")\n",
    "\n",
    "    # Concurrency\n",
    "    with ThreadPoolExecutor(max_workers=max(1, int(workers))) as ex:\n",
    "        futs = {ex.submit(process_one_resume, jd, p, structured_llm): p for p in selected_files}\n",
    "        for fut in as_completed(futs):\n",
    "            p = futs[fut]\n",
    "            try:\n",
    "                rep = fut.result()\n",
    "                if rep:\n",
    "                    reports.append(rep)\n",
    "                    # write per-candidate JSON immediately\n",
    "                    out_path = Path(\"reports\") / f\"{rep['candidate_name']}_report.json\"\n",
    "                    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(rep, f, indent=2, ensure_ascii=False)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed {p.name}: {e}\")\n",
    "\n",
    "    # CSV summary\n",
    "    if reports:\n",
    "        summary_fields = [\n",
    "            \"candidate_name\", \"job_title\", \"final_score\", \"final_score_deterministic\",\n",
    "            \"match_score\", \"longest_tenure_months\", \"city_tier_match\",\n",
    "            \"missing_required_skills\", \"matched_required_skills\"\n",
    "        ]\n",
    "        csv_path = Path(\"reports\") / \"summary.csv\"\n",
    "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=summary_fields)\n",
    "            w.writeheader()\n",
    "            for r in reports:\n",
    "                row = {k: r.get(k) for k in summary_fields}\n",
    "                # lists -> semicolon string for CSV\n",
    "                for k in (\"missing_required_skills\", \"matched_required_skills\"):\n",
    "                    v = row.get(k)\n",
    "                    if isinstance(v, list):\n",
    "                        row[k] = \"; \".join(v)\n",
    "                w.writerow(row)\n",
    "        logging.info(f\"Wrote {csv_path}\")\n",
    "    return reports\n",
    "\n",
    "# ========== CLI ==========\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    # parser = argparse.ArgumentParser(description=\"Run NexResume matching pipeline (refactored)\")\n",
    "    # parser.add_argument('--job', type=str, required=True, help=\"Path to job_description.yml\")\n",
    "    # parser.add_argument('--resumes', type=str, required=True, help=\"Path to folder containing resumes (.pdf/.txt)\")\n",
    "    # parser.add_argument('--workers', type=int, default=4, help=\"Max concurrent resumes\")\n",
    "    # parser.add_argument('--model', type=str, default=\"gpt-4o-mini\", help=\"OpenAI model name\")\n",
    "    # parser.add_argument('--topk', type=int, default=None, help=\"Absolute number of resumes to pass to LLM after prefilter\")\n",
    "    # parser.add_argument('--topk-frac', type=float, default=0.4, help=\"Fraction of resumes to pass if --topk is not set\")\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "job_description_file = r\"C:\\Users\\Lenovo\\resume_matcher\\jd.yaml\"\n",
    "resumes_folder = r\"C:\\Users\\Lenovo\\resume_matcher\\resumes\"\n",
    "topk = 2\n",
    "Path(\"reports\").mkdir(exist_ok=True)\n",
    "\n",
    "t0 = time.time()\n",
    "reports = process_all(job_description_file=job_description_file, resumes_folder=resumes_folder, topk=topk)\n",
    "logging.info(f\"Done processing resumes in {time.time() - t0:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a53a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "NexResume Pipeline (Simplified, No Chunking):\n",
    "- Robust PDF parsing (pypdf -> pdfminer.six fallback)\n",
    "- Structured LLM outputs via Pydantic (no more JSON guessing)\n",
    "- Deterministic scoring (optional, based on JD weights)\n",
    "- Concurrency + retries + logging\n",
    "- CSV summary aggregation\n",
    "\n",
    "Usage:\n",
    "  python nexresume_refactor.py --job path/to/job.yml --resumes path/to/resumes_folder [--workers 4]\n",
    "\n",
    "Requires:\n",
    "  pip install langchain-openai langchain pydantic backoff pypdf pdfminer.six pyyaml numpy sentence-transformers torch --upgrade\n",
    "  export OPENAI_API_KEY=...\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "import csv\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# LangChain (modern imports)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "import backoff\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "# ========== Logging ==========\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")\n",
    "\n",
    "# ========== IO helpers ==========\n",
    "\n",
    "def load_yaml_job_description(path: str) -> Dict[str, Any]:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        jd = yaml.safe_load(f) or {}\n",
    "    return jd\n",
    "\n",
    "\n",
    "def _read_pdf_pypdf(file_path: str) -> str:\n",
    "    try:\n",
    "        from pypdf import PdfReader\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    try:\n",
    "        text = []\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            reader = PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                try:\n",
    "                    text.append(page.extract_text() or \"\")\n",
    "                except Exception:\n",
    "                    text.append(\"\")\n",
    "        return \"\\n\".join(text)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"pypdf failed on {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def _read_pdf_pdfminer(file_path: str) -> str:\n",
    "    try:\n",
    "        from pdfminer.high_level import extract_text\n",
    "        return extract_text(file_path) or \"\"\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"pdfminer failed on {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def load_resume_text(file_path: str) -> str:\n",
    "    file_path = str(file_path)\n",
    "    if file_path.lower().endswith('.txt'):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not read TXT {file_path}: {e}\")\n",
    "            return \"\"\n",
    "    elif file_path.lower().endswith('.pdf'):\n",
    "        text = _read_pdf_pypdf(file_path)\n",
    "        if not text.strip():\n",
    "            text = _read_pdf_pdfminer(file_path)\n",
    "        if not text.strip():\n",
    "            logging.warning(f\"Could not extract text from PDF {file_path}\")\n",
    "        return text\n",
    "    else:\n",
    "        logging.warning(f\"Unsupported resume format: {file_path}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def safe_candidate_name_from_file(file_name: str) -> str:\n",
    "    stem = Path(file_name).stem\n",
    "    return re.sub(r\"[^A-Za-z0-9_.-]\", \"_\", stem)\n",
    "\n",
    "# ========== Pydantic schema for structured output ==========\n",
    "\n",
    "class MatchReport(BaseModel):\n",
    "    matched_required_skills: List[str] = []\n",
    "    missing_required_skills: List[str] = []\n",
    "    matched_optional_skills: List[str] = []\n",
    "    education_match: str\n",
    "    experience_match: str\n",
    "    keywords_matched: List[str] = []\n",
    "    soft_skills_match: List[str] = []\n",
    "    resume_summary: str\n",
    "    match_score: float = Field(ge=0, le=1)\n",
    "    city_tier_match: bool\n",
    "    longest_tenure_months: int\n",
    "    final_score: int = Field(ge=0, le=100)\n",
    "    detected_city: Optional[str] = None\n",
    "    detected_city_tier: Optional[int] = None\n",
    "    max_job_gap_months: Optional[int] = None\n",
    "    stability_score: Optional[float] = Field(default=None, ge=0, le=1)\n",
    "\n",
    "# ========== Prompt ==========\n",
    "\n",
    "PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "    \"system\",\n",
    "    \"You are an expert technical recruiter and data scientist. \"\n",
    "    \"Your job is to read a job description (JD) and a resume, then return a STRICT JSON object matching the schema. \"\n",
    "    \"Be precise, consistent, and terse. If the information is not present, return a sensible null/empty value rather than guessing. \"\n",
    "    \"NEVER add commentary, markdown, or keys not in the schema.\"\n",
    "),\n",
    "(\n",
    "    \"user\",\n",
    "    \"<OBJECTIVE>\\n\"\n",
    "    \"Evaluate the resume against the JD and produce high-quality, schema-valid JSON capturing skills, education, experience fit, city-tier & gaps, longest tenure, and a calibrated final_score.\\n\"\n",
    "    \"\\n\"\n",
    "    \"<INPUTS>\\n\"\n",
    "    \"Job Description (YAML): {job_description}\\n\"\n",
    "    \"Resume : {resume_text}\\n\"\n",
    "    \"\\n\"\n",
    "     \"<RUBRIC FOR final_score (100-point scale)>\\n\"\n",
    "    \"Weightage:\\n\"\n",
    "    \"- required skills coverage: 40%\\n\"\n",
    "    \"- optional skills coverage: 15%\\n\"\n",
    "    \"- experience fit (years/recency/scope): 15%\\n\"\n",
    "    \"- education fit: 10%\\n\"\n",
    "    \"- location fit: 5% (true if city_tier meets JD or is unspecified)\\n\"\n",
    "    \"- stability: 10% (longest_tenure_months; full credit at 48 months; scale proportionally)\\n\"\n",
    "    \"- diversity by city tier: 5% bonus (Tier-3 > Tier-2 > Tier-1; score 100 for T3, 60 for T2, 0 for T1)\\n\"\n",
    "    \"\\n\"\n",
    "    \"<SCHEMA AND CONSTRAINTS>\\n\"\n",
    "    \"You must return a single JSON object with the following keys and constraints:\\n\"\n",
    "    \"- matched_required_skills: string[]\\n\"\n",
    "    \"- missing_required_skills: string[]\\n\"\n",
    "    \"- matched_optional_skills: string[]\\n\"\n",
    "    \"- education_match: string\\n\"\n",
    "    \"- experience_match: string\\n\"\n",
    "    \"- keywords_matched: string[]\\n\"\n",
    "    \"- soft_skills_match: string[]\\n\"\n",
    "    \"- resume_summary: string\\n\"\n",
    "    \"- match_score: number in [0,1]\\n\"\n",
    "    \"- city_tier_match: boolean\\n\"\n",
    "    \"- longest_tenure_months: integer >= 0\\n\"\n",
    "    \"- final_score: integer in [0,100]\\n\"\n",
    "    \"- detected_city: string|null\\n\"\n",
    "    \"- detected_city_tier: 1|2|3|null\\n\"\n",
    "    \"- max_job_gap_months: integer|null\\n\"\n",
    "    \"- stability_score: number in [0,1]|null\\n\"\n",
    "    \"\\n\"\n",
    "    \"<ROBUSTNESS & STYLE>\\n\"\n",
    "    \"- Keep outputs concise; arrays deduplicated and normalized to lowercase where appropriate.\\n\"\n",
    "    \"- Never include markdown or commentaryâ€”only the JSON object.\\n\"\n",
    "    \"\\n\"\n",
    "    \"<OUTPUT> Return ONLY the JSON object.\"\n",
    ")\n",
    "])\n",
    "\n",
    "# ========== Embeddings (pre-filter) ==========\n",
    "\n",
    "def _cosine(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    if a is None or b is None:\n",
    "        return -1.0\n",
    "    na = np.linalg.norm(a); nb = np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0:\n",
    "        return -1.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "_embedder: Optional[SentenceTransformerEmbeddings] = None\n",
    "\n",
    "def get_embedder() -> SentenceTransformerEmbeddings:\n",
    "    global _embedder\n",
    "    if _embedder is None:\n",
    "        _embedder = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    return _embedder\n",
    "\n",
    "def embed_text(text: str) -> np.ndarray:\n",
    "    emb = get_embedder().embed_query(text or \"\")\n",
    "    return np.array(emb, dtype=np.float32)\n",
    "\n",
    "def prefilter_resumes(jd: Dict[str, Any], resume_paths: List[Path], texts: List[str], topk: Optional[int] = None, topk_frac: float = 0.4) -> List[Tuple[Path, float]]:\n",
    "    jd_text = yaml.dump(jd, sort_keys=False)\n",
    "    jd_vec = embed_text(jd_text)\n",
    "\n",
    "    sims: List[Tuple[int, float]] = []\n",
    "    for i, t in enumerate(texts):\n",
    "        try:\n",
    "            v = embed_text(t)\n",
    "            sims.append((i, _cosine(jd_vec, v)))\n",
    "        except Exception:\n",
    "            sims.append((i, -1.0))\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    n = len(resume_paths)\n",
    "    k = int(topk) if topk is not None else int(np.ceil(max(1, n) * float(topk_frac)))\n",
    "    k = max(1, min(n, k))\n",
    "\n",
    "    selected = [(resume_paths[i], score) for i, score in sims[:k]]\n",
    "    return selected\n",
    "\n",
    "# ========== LLM client ==========\n",
    "key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "base = os.getenv(\"OPENROUTER_BASE\", \"https://openrouter.ai/api/v1\")\n",
    "model_name = \"qwen/qwen2.5-vl-72b-instruct:free\"\n",
    "\n",
    "def make_llm(model: str = \"gpt-4o-mini\", temperature: float = 0.6):\n",
    "    llm = ChatOpenAI(model=model_name, temperature=temperature, api_key=key, base_url=base)\n",
    "    return llm\n",
    "\n",
    "# ========== Retry wrapper ==========\n",
    "\n",
    "@backoff.on_exception(backoff.expo, Exception, max_time=90)\n",
    "def call_llm_structured(structured_llm, jd_dict: Dict[str, Any], resume_text: str) -> MatchReport:\n",
    "    msg = PROMPT.format(job_description=yaml.dump(jd_dict, sort_keys=False), resume_text=resume_text)\n",
    "    return structured_llm.invoke(msg)\n",
    "\n",
    "# ========== Per-resume processing ==========\n",
    "\n",
    "def clean_text_v2(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = re.sub(r\"```(?:json)?\\n?|```\", \"\", text, flags=re.IGNORECASE).strip()\n",
    "    json_start = re.search(r'[\\{\\[]', text)\n",
    "    if json_start:\n",
    "        text = text[json_start.start():]\n",
    "    return text.strip()\n",
    "\n",
    "def process_one_resume(jd: Dict[str, Any], resume_path: Path, structured_llm) -> Optional[Dict[str, Any]]:\n",
    "    text = load_resume_text(str(resume_path))\n",
    "    if not text.strip():\n",
    "        logging.warning(f\"Empty/unsupported resume: {resume_path.name}; skipping.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        r = call_llm_structured(structured_llm, jd, text)\n",
    "        cleaned_result = clean_text_v2(r.content)\n",
    "        parsed = json.loads(cleaned_result)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"LLM error on {resume_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "    candidate = safe_candidate_name_from_file(resume_path.name)\n",
    "    report = {\n",
    "        \"candidate_name\": candidate,\n",
    "        \"job_title\": jd.get(\"Job_Title\") or jd.get(\"job_title\"),\n",
    "        **parsed,\n",
    "    }\n",
    "    return report\n",
    "\n",
    "# ========== Batch processing ==========\n",
    "\n",
    "def process_all(job_description_file: str, resumes_folder: str, workers: int = 4, model: str = \"gpt-4o-mini\", topk: Optional[int] = None, topk_frac: float = 0.4) -> None:\n",
    "    reports_dir = Path(\"reports\"); reports_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    jd = load_yaml_job_description(job_description_file)\n",
    "    structured_llm = make_llm(model=model)\n",
    "\n",
    "    resume_files = [Path(resumes_folder) / fn for fn in os.listdir(resumes_folder)\n",
    "                    if fn.lower().endswith((\".pdf\", \".txt\"))]\n",
    "\n",
    "    reports: List[Dict[str, Any]] = []\n",
    "\n",
    "    resume_texts = [load_resume_text(str(p)) for p in resume_files]\n",
    "\n",
    "    ranked = prefilter_resumes(jd, resume_files, resume_texts, topk=topk, topk_frac=topk_frac)\n",
    "    selected_files = [p for p, _ in ranked]\n",
    "    logging.info(f\"Pre-filter selected {len(selected_files)}/{len(resume_files)} resumes via embeddings\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max(1, int(workers))) as ex:\n",
    "        futs = {ex.submit(process_one_resume, jd, p, structured_llm): p for p in selected_files}\n",
    "        for fut in as_completed(futs):\n",
    "            p = futs[fut]\n",
    "            try:\n",
    "                rep = fut.result()\n",
    "                if rep:\n",
    "                    reports.append(rep)\n",
    "                    out_path = Path(\"reports\") / f\"{rep['candidate_name']}_report.json\"\n",
    "                    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(rep, f, indent=2, ensure_ascii=False)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed {p.name}: {e}\")\n",
    "\n",
    "    if reports:\n",
    "        summary_fields = [\n",
    "            \"candidate_name\", \"job_title\", \"final_score\",\n",
    "            \"match_score\", \"longest_tenure_months\", \"city_tier_match\",\n",
    "            \"missing_required_skills\", \"matched_required_skills\"\n",
    "        ]\n",
    "        csv_path = Path(\"reports\") / \"summary.csv\"\n",
    "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=summary_fields)\n",
    "            w.writeheader()\n",
    "            for r in reports:\n",
    "                row = {k: r.get(k) for k in summary_fields}\n",
    "                for k in (\"missing_required_skills\", \"matched_required_skills\"):\n",
    "                    v = row.get(k)\n",
    "                    if isinstance(v, list):\n",
    "                        row[k] = \"; \".join(v)\n",
    "                w.writerow(row)\n",
    "        logging.info(f\"Wrote {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
